{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdNDrDtpLEze2bLxoR7XWk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisgustavoreimberg/CurriculOn/blob/master/Desafio_Imersao_Alura_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Realizando configurações iniciais"
      ],
      "metadata": {
        "id": "9TbkW0rSaI-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação do SDK do Google"
      ],
      "metadata": {
        "id": "mUHcKYqTaahe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "C0Zo3qcPadbE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando dependências"
      ],
      "metadata": {
        "id": "S8hmGKjYafH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import time\n",
        "from google.api_core.exceptions import TooManyRequests\n",
        "import logging"
      ],
      "metadata": {
        "id": "ghpalIUmalzW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando o modelo"
      ],
      "metadata": {
        "id": "D6SM_7-QaoGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Configurando o modelo"
      ],
      "metadata": {
        "id": "xzVhtGlOa0SF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inserindo API Key"
      ],
      "metadata": {
        "id": "z42oWj5ca4zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key = userdata.get('apiKey'))"
      ],
      "metadata": {
        "id": "TxUUHgzRaq1O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando padrâmetros do modelo"
      ],
      "metadata": {
        "id": "XRfXG_SYa9WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CONFIGURANDO PARÂMETROS DO MODELO\n",
        "generation_config = genai.GenerationConfig(\n",
        "  candidate_count = 1,\n",
        ")\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_ONLY_HIGH\",\n",
        "    \"HATE\": \"BLOCK_ONLY_HIGH\",\n",
        "    \"SEXUAL\": \"BLOCK_ONLY_HIGH\",\n",
        "    \"DANGEROUS\": \"BLOCK_ONLY_HIGH\"\n",
        "}\n",
        "\n",
        "#CONFIGURANDO INSTRUÇÕES DO SISTEMA PARA DIRECIONAR O CONTEXTO, PERSONA E REGRAS\n",
        "system_instruction = [\n",
        "    \"Você é um atendente de uma central de emergência via chat\",\n",
        "    \"Você deve realizar o atendimento inicial e classificar de forma discreta se é uma emergência ou não(um trote)\",\n",
        "    \"Você deve realizar no mínimo 3 pergunta para o atendimento\",\n",
        "    \"Você deve buscar informações sobre o ocorrido, identificando no mínimo o local do ocorrido e quantidade de envolvidos\"\n",
        "    \"O atendimento deve ser guiado por mensagens ou questionamentos simples e únicos\"\n",
        "]"
      ],
      "metadata": {
        "id": "-Q2Hksf2bA5d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando o modelo"
      ],
      "metadata": {
        "id": "mkSA0D7Db8bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name = \"gemini-1.5-pro-latest\",\n",
        "    generation_config = generation_config,\n",
        "    system_instruction = system_instruction,\n",
        "    safety_settings = safety_settings\n",
        ")"
      ],
      "metadata": {
        "id": "lIYK3z3UcFLn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Executando o Chat"
      ],
      "metadata": {
        "id": "Mfyewn4EeJQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incluindo métodos úteis para reaproveitamento de trechos de código envolvendo mensagems de console"
      ],
      "metadata": {
        "id": "XvEELbAcePmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def console_clear():\n",
        "    os.system('cls') #COMANDO PARA LIMPAR CONSOLE WINDOWS\n",
        "\n",
        "def console_message(message, role = 'SYSTEM', must_clear = False, with_header = False, with_footer = False):\n",
        "    if with_header:\n",
        "        print(\"----------------------------------------------\")\n",
        "        print(\"-- S.O.S -------------------------------------\")\n",
        "    if(type(message) == str):\n",
        "        message = [message]\n",
        "    for msg in message:\n",
        "        print(f\"{role.upper()}: {msg}\")\n",
        "    if with_footer:\n",
        "        print(\"------------------------versão de testes/estudo\")\n",
        "        print(\"----------------------------------------------\")\n",
        "\n",
        "def console_question(message, role = 'SYSTEM', must_get_answer = True):\n",
        "    question = f\"{role.upper()}: {message}\\nUSER: \"\n",
        "    answer = input(question)\n",
        "    if must_get_answer:\n",
        "        while not answer:\n",
        "            console_clear()\n",
        "            console_message(\"ATENÇÃO, RESPONSA A PERGUNTA CONFORME SOLICITADO\")\n",
        "            answer = input(question)\n",
        "    return answer\n",
        "\n",
        "def console_chat_history(chat_history):\n",
        "    time.sleep(5)\n",
        "    console_message(\"INÍCIO HISTÓRICO\", must_clear= True, with_header = True)\n",
        "\n",
        "    if(len(chat.history) > 0):\n",
        "      for content in chat_history:\n",
        "        console_message(content.parts[0].text, content.role)\n",
        "\n",
        "    console_message(\"FIM\", with_footer = True)"
      ],
      "metadata": {
        "id": "IUkf2d3zeOGL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incluindo variaveis utilizadas no chat"
      ],
      "metadata": {
        "id": "QR-d6LSYvSd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.getLogger(\"tornado.access\").setLevel(logging.CRITICAL) #removendo logging do console\n",
        "\n",
        "user_escape_mensage = \"SAIR\"\n",
        "bot_escape_message = \"#FIM#\"\n",
        "\n",
        "mensagens_iniciais_usuario = [\n",
        "    \"ATENÇÃO, UTILIZE O SERVIÇO COM RESPONSABILIDADE\",\n",
        "    \"RESPONDA AS PERGUNTAS CORRETAMENTE PARA DEFINIRMOS O ATENDIMENTO EMERGENCIAL\",\n",
        "    f\"PARA FINALIZAR SEU ATENDIMENTO DIGITE \\\"{user_escape_mensage}\\\"\"]\n",
        "\n",
        "initial_bot_prompt = f\"Quando você se decidir sobre o atendimento, envie uma mensagem no seguinte padrão: Quando é um trote ou não emergência: 'Estarei finalizando sua ligação{bot_escape_message}' e Quando é uma emergência: 'Estamos enviando uma unidade de atendimento o mais rápido possível{bot_escape_message}'\""
      ],
      "metadata": {
        "id": "ujVCBvQHvX62"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando estrutura dos chats"
      ],
      "metadata": {
        "id": "DF4NLzw2eui5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  #INICIANDO O CHAT\n",
        "  console_message(message = mensagens_iniciais_usuario, with_header = True)\n",
        "\n",
        "  #INICIANDO O CHAT E ENVIANDO PROMPT INICIAL\n",
        "  chat = model.start_chat(history=[])\n",
        "  ai_response = chat.send_message(initial_bot_prompt).text\n",
        "\n",
        "  #FLUXO DO CHAT\n",
        "  while not bot_escape_message in ai_response:\n",
        "    time.sleep(5)#DIMINUINDO FREQUÊNCIA DAS REQUISIÇÕES PARA EVITAR ERRO DE TOO MANY REQUESTS\n",
        "    prompt = console_question(ai_response, \"BOT\")\n",
        "    if prompt == user_escape_mensage:\n",
        "      console_message(\"ATENDIMENTO FINALIZADO PELO USUÁRIO\")\n",
        "      break\n",
        "    ai_response = chat.send_message(prompt).text\n",
        "\n",
        "  console_message(ai_response.replace(bot_escape_message, \"\"), \"BOT\")\n",
        "\n",
        "except TooManyRequests:\n",
        "  #CAPTURANDO MENSAGEM DE MUITAS REQUISIÇÕES(RATE LIMIT)\n",
        "  console_message(\"NOSSOS SISTEMAS ESTÃO MUITO OCULPADOS. SEU ATENDIMENTO ESTÁ SENDO TRANSFERIDO PARA UM AGENTE!\", must_clear = True, with_header = True)\n",
        "\n",
        "except Exception as e:\n",
        "  #CAPTURANDO ERROS\n",
        "  console_message(f\"OCORREU UM ERRO DURANTE A REQUISIÇÃO. SEU ATENDIMENTO ESTÁ SENDO TRANSFERIDO AGENTE!\", must_clear = True, with_header = True)\n",
        "\n",
        "finally:\n",
        "  #FINALIZANDO E MOSTRANDO O CONSOLE\n",
        "  console_message(\"ATENDIMENTO FINALIZADO\", with_footer = True)\n",
        "  console_chat_history(chat.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "yGs9bnxtesUB",
        "outputId": "3a1e2078-c100-4d4c-c5a4-cbc4b543afe5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------\n",
            "-- S.O.S -------------------------------------\n",
            "SYSTEM: ATENÇÃO, UTILIZE O SERVIÇO COM RESPONSABILIDADE\n",
            "SYSTEM: RESPONDA AS PERGUNTAS CORRETAMENTE PARA DEFINIRMOS O ATENDIMENTO EMERGENCIAL\n",
            "SYSTEM: PARA FINALIZAR SEU ATENDIMENTO DIGITE \"SAIR\"\n",
            "BOT: Olá! Qual o endereço da emergência? \n",
            "\n",
            "USER: Rua xyz\n",
            "BOT: Ok, Rua xyz. Pode me dizer qual o número da casa, por favor? E o que está acontecendo? \n",
            "\n",
            "USER: altura do numero 33, acidente de transito\n",
            "BOT: Rua xyz, número 33. Entendi. Há quantas pessoas envolvidas no acidente? \n",
            "\n",
            "USER: Apenas uma pessoa, um dos motoristas\n",
            "BOT: Estamos enviando uma unidade de atendimento o mais rápido possível \n",
            "\n",
            "SYSTEM: ATENDIMENTO FINALIZADO\n",
            "------------------------versão de testes/estudo\n",
            "----------------------------------------------\n",
            "----------------------------------------------\n",
            "-- S.O.S -------------------------------------\n",
            "SYSTEM: INÍCIO HISTÓRICO\n",
            "USER: Quando você se decidir sobre o atendimento, envie uma mensagem no seguinte padrão: Quando é um trote ou não emergência: 'Estarei finalizando sua ligação#FIM#' e Quando é uma emergência: 'Estamos enviando uma unidade de atendimento o mais rápido possível#FIM#'\n",
            "MODEL: Olá! Qual o endereço da emergência? \n",
            "\n",
            "USER: Rua xyz\n",
            "MODEL: Ok, Rua xyz. Pode me dizer qual o número da casa, por favor? E o que está acontecendo? \n",
            "\n",
            "USER: altura do numero 33, acidente de transito\n",
            "MODEL: Rua xyz, número 33. Entendi. Há quantas pessoas envolvidas no acidente? \n",
            "\n",
            "USER: Apenas uma pessoa, um dos motoristas\n",
            "MODEL: Estamos enviando uma unidade de atendimento o mais rápido possível#FIM# \n",
            "\n",
            "SYSTEM: FIM\n",
            "------------------------versão de testes/estudo\n",
            "----------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}